# 1.依赖关系：
    GPU ==决定==》CUDA版本
       CUDA版本 ==决定==》torch\torchvison\torchaudio 的版本（即pytorch版本)
          pytorch版本 ==决定==》python版本
          pytorch版本 ==决定==》transformers库版本
          pytorch版本  ==》决定==》openmind library库

    简言之：物理显卡 → 驱动 → CUDA → PyTorch → Python → Transformers库或openmind库

========================pytorch上层使用transformers================================

# 2.HuggingFace、transformer关系
    transformer架构--由hugging Face实现发布transformer库。是NLP的核心库。
# 3.HuggingFace工具家族库
    --transformers 预训练库
    --Datasets     为transformers库提供数据输入，处理与增强
    --Evaluate    模型验证阶段，与transformers流程无缝集成
    --Tokenizers  预处理输入数据，高效分词文本编码，为transformers提供token IDs
    --PEFT          扩展transformers微调能力（LoRA、Adapter）
    --Accelerate    简化分布式训练，支持多GPU/TPU加速。

========================或pytorch上层使用openmind================================
# 4. openmind
    openmind可视为“昇腾生态的huggingface”，社区为魔乐社区。如果项目需完全使用国产化工具链则使用。
    包含
    --openmind library开发套件。

